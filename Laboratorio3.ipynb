{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Universidad del valle de Guatemala  \n",
    "Dpto. Ciencias de la computacion  \n",
    "Inteligencia Artificial  \n",
    "Alberto Suriano  \n",
    "\n",
    "Laboratorio 3  \n",
    "Andres Quinto - 18288  \n",
    "Marlon Hernández - 15177\n",
    "\n",
    "- Link del repositorio: https://github.com/AndresQuinto5/IA_LAB3.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1 - Preguntas Teóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Responda a cada de las siguientes preguntas de forma clara y lo más completamente posible.\n",
    "1. Explique la diferencia entre descenso de gradiente, descenso de gradiente por mini batches y descenso de gradiente estocástico. Asegúrese de mencionar las ventajas y desventajas de cada enfoque.\n",
    "\n",
    "    **Descenso de Gradiente (DG)**: Este método utiliza todo el conjunto de datos para calcular el gradiente de la función de coste. Es muy preciso, pero puede ser muy lento y costoso en términos de recursos computacionales, especialmente cuando el conjunto de datos es grande. Como nos explicaba Suriano durante la clase, en su formula en cada iteracion le pasamos el dataset completo.\n",
    "\n",
    "    - **Ventajas**: Converge a un mínimo global en funciones de coste convexas.\n",
    "\n",
    "    - **Desventajas**: Puede ser muy lento y costoso en términos de recursos computacionales con conjuntos de datos grandes.\n",
    "\n",
    "    **Descenso de Gradiente Estocástico (DGE)**: Este método utiliza solo un ejemplo aleatorio del conjunto de datos en cada iteración para calcular el gradiente. Es mucho más rápido y menos costoso en términos de recursos computacionales, pero los resultados pueden variar mucho debido a la naturaleza aleatoria del método. Como vimos en clase y Suriano dibujando la grafica, esto crea tambien ruido visualmente por su aletoriedad.\n",
    "\n",
    "    - **Ventajas**: Es rápido y eficiente en términos de memoria. Puede escapar de mínimos locales en funciones de coste no convexas.\n",
    "\n",
    "    - **Desventajas**: Puede tener una convergencia inestable debido a la naturaleza aleatoria del método.\n",
    "\n",
    "    **Descenso de Gradiente por Mini-Batches (DGMB)**: Este método es una combinación de DG y DGE. Utiliza un pequeño subconjunto aleatorio del conjunto de datos en cada iteración para calcular el gradiente. Es más rápido que DG y más estable que DGE. A diferencia del anterior, este toma batches de 3 features de manera aleatoria y elige el que forme la linea mas smooth, de modo que de forma visual la funcion tiene menos ruido y es rapida.\n",
    "\n",
    "    - **Ventajas**: Equilibra la eficiencia computacional y la estabilidad de la convergencia.\n",
    "\n",
    "    - **Desventajas**: El tamaño del mini-batch puede afectar la calidad de la convergencia y debe ser ajustado cuidadosamente.\n",
    "\n",
    "    *Bibliography consulted:*  \n",
    "        [Clase Teórica Semana del 28](https://uvg.instructure.com/courses/33907/pages/sgd-features-redes-neuronales?module_item_id=827995)\n",
    "\n",
    "    [Guía rápida: Descenso de gradiente: Batch Vs Stochastic Vs Mini-Batch](https://ichi.pro/es/guia-rapida-descenso-de-gradiente-batch-vs-stochastic-vs-mini-batch-16928601580448#google_vignette)\n",
    "2. Compare y contraste técnicas de extracción de features (feature extraction) y selección de features (feature selection) en machine learning. De ejemplos de escenarios donde cada técnica sería más apropiada.\n",
    "\n",
    "    **Extracción de características (Feature Extraction)**: Este proceso implica la transformación de los datos de entrada en un conjunto de características que representan mejor la información subyacente. Por ejemplo, en el procesamiento de imágenes, podríamos extraer características como los bordes, los colores y las texturas.\n",
    "\n",
    "    - *Ventajas*: Permite reducir la dimensionalidad de los datos y puede mejorar el rendimiento del modelo al centrarse en las características más informativas.\n",
    "\n",
    "    - *Desventajas*: La elección de las características a extraer puede ser difícil y depende en gran medida del problema específico.\n",
    "\n",
    "    - *Escenario de uso*: La extracción de características es especialmente útil cuando trabajamos con datos de alta dimensionalidad, como imágenes o texto.\n",
    "\n",
    "    **Selección de características (Feature Selection)**: Este proceso implica seleccionar un subconjunto de las características existentes sin cambiarlas. Por ejemplo, podríamos seleccionar las características que tienen la mayor correlación con la variable objetivo. Esto fue algo que puse en practica en el Laboratorio 2 de League of legends, donde en base a mis conocimientos previos del genero de juego podia intuir que variables de estar presentes podia tomar y lo comprobe por medio de la correlacion que existia entre ellas y la variable objetivo (Victoria de cierto equipo)\n",
    "\n",
    "    - *Ventajas*: Permite reducir la dimensionalidad de los datos sin perder información y puede mejorar el rendimiento del modelo al eliminar características irrelevantes o redundantes.\n",
    "\n",
    "    - *Desventajas*: La elección de las características a seleccionar puede ser difícil y depende en gran medida del problema específico.\n",
    "\n",
    "    - *Escenario de uso*: La selección de características es especialmente útil cuando tenemos un conjunto de datos con muchas características y queremos reducir la complejidad del modelo.\n",
    "\n",
    "    Tanto la extracción como la selección de características son técnicas importantes en el aprendizaje automático que nos ayudan a lidiar con la maldición de la dimensionalidad y a mejorar el rendimiento de nuestros modelos. La elección entre uno y otro depende en gran medida del problema específico que estemos tratando de resolver y de nuestro criterio para realizar una selección de metodología.\n",
    "\n",
    "    *Bibliography consulted:*  \n",
    "    [Clase Teórica Semana del 28](https://uvg.instructure.com/courses/33907/pages/sgd-features-redes-neuronales?module_item_id=827995)\n",
    "\n",
    "    [Diferencia entre la selección y extracción de características](https://www.geeksforgeeks.org/difference-between-feature-selection-and-feature-extraction/)\n",
    "\n",
    "3. Describa la arquitectura y el funcionamiento de un perceptrón de una sola capa (un tipo de red neuronal sin backpropagation). Explique cómo aprende y la forma en la que actualiza sus parámetros.  \n",
    "\n",
    "    **Arquitectura de un Perceptrón de una sola capa**: Un perceptrón es una neurona artificial o una unidad de red neuronal que realiza ciertos cálculos para detectar capacidades de datos de entrada1. Un perceptrón de una sola capa tiene solo dos capas: una capa de entrada y una capa de salida.\n",
    "\n",
    "    - *Capa de entrada*: Los valores de entrada llegan a la red neuronal. En esta capa, cada “neurona” recibe un único valor de entrada.\n",
    "    - *Capa de salida*: La capa de salida contiene las variables (dependientes) de destino.\n",
    "\n",
    "    **Funcionamiento de un Perceptrón de una sola capa**: Cada nodo en la capa de salida toma un promedio ponderado de todas sus entradas. La suma ponderada de las entradas se pasa a través de una función de activación para producir la salida.\n",
    "\n",
    "    **Aprendizaje y actualización de parámetros**: Un perceptrón aprende ajustando los pesos de las señales de entrada en función del error que produce. El error se calcula como la diferencia entre la salida deseada y la salida real del perceptrón. Los pesos se actualizan utilizando la regla de aprendizaje del perceptrón, que es una regla de aprendizaje simple.\n",
    "\n",
    "    **Planteamiento matematico visto en clase:**  Un perceptrón de una sola capa se puede describir matemáticamente de la siguiente manera:\n",
    "\n",
    "    **A continuacion, veremos cual es el planteamiento matematico de la teoria, como lo vimos con suriano en clase**:\n",
    "    1. **Suma ponderada de las entradas**: La salida de un perceptrón es la suma ponderada de sus entradas más un término de sesgo. Matemáticamente, esto se puede expresar como:\n",
    "\n",
    "        $$z = \\sum_{i=0}^{n} w_i x_i = w^T x$$\n",
    "\n",
    "        donde:\n",
    "        - $w_i$ son los pesos asociados a cada entrada $x_i$.\n",
    "        - $w^T$ es el vector transpuesto de los pesos.\n",
    "        - $x$ es el vector de las entradas.\n",
    "        - $z$ es la entrada neta o suma ponderada de las entradas.\n",
    "\n",
    "    2. **Función de activación**: La entrada neta se pasa a través de una función de activación para producir la salida. En el caso de un perceptrón, esta función de activación es una función escalón²:\n",
    "\n",
    "        $$y = \\Phi(z) = \n",
    "        \\begin{cases} \n",
    "        1 & \\text{si } z \\geq 0 \\\\\n",
    "        0 & \\text{si } z < 0 \n",
    "        \\end{cases}$$\n",
    "\n",
    "        donde:\n",
    "        - $\\Phi$ es la función de activación.\n",
    "        - $y$ es la salida del perceptrón.\n",
    "\n",
    "    3. **Regla de aprendizaje**: Los pesos del perceptrón se actualizan en función del error, que es la diferencia entre la salida deseada y la salida real. La regla de aprendizaje del perceptrón se puede expresar como³:\n",
    "\n",
    "        $$w_{i}(new) = w_{i}(old) + \\eta (d - y) x_{i}$$\n",
    "\n",
    "        donde:\n",
    "        - $w_{i}(new)$ y $w_{i}(old)$ son los pesos nuevos y antiguos, respectivamente.\n",
    "        - $\\eta$ es la tasa de aprendizaje.\n",
    "        - $d$ es la salida deseada.\n",
    "        - $y$ es la salida actual.\n",
    "        - $x_{i}$ es la entrada i-ésima.\n",
    "\n",
    "        *Bibliography consulted:*  \n",
    "        [Clase Teórica Semana del 28](https://uvg.instructure.com/courses/33907/pages/sgd-features-redes-neuronales?module_item_id=827995)  \n",
    "        \n",
    "        [Formulación matemática del Perceptrón | Interactive Chaos](https://interactivechaos.com/es/manual/tutorial-de-machine-learning/formulacion-matematica-del-perceptron)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Ejercicios Prácticos\n",
    "### Task 2.1 - Gradiente Descendiente Estocástico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nImplemente el descenso de gradiente estocástico, el descenso de gradiente y el descenso de gradiente por mini\\nbatches para una función polinómica de grado 3. Luego, grafique la función aproximada por cada uno de los\\nmétodos solicitados y la distribución real de puntos.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Implemente el descenso de gradiente estocástico, el descenso de gradiente y el descenso de gradiente por mini\n",
    "batches para una función polinómica de grado 3. Luego, grafique la función aproximada por cada uno de los\n",
    "métodos solicitados y la distribución real de puntos.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
